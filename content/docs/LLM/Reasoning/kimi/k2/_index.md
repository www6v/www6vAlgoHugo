---
title: kimi k2
date: 2024-02-06 18:35:28
weight: 1
---





# 论文
https://github.com/MoonshotAI/Kimi-K2?tab=readme-ov-file 

https://moonshotai.github.io/Kimi-K2/ 

https://arxiv.org/pdf/2507.20534 



---

## 概述

- [Kimi K2](https://arxiv.org/abs/2507.20534) 标志着从传统静态大语言模型（LLM）向**智能体智能（agentic intelligence）**的转变。在这种新范式下，模型通过与动态环境的交互主动学习，而不仅仅依赖预先收集的数据集。其目标是赋予大语言模型自主感知、规划、推理和行动的能力，使其能够突破训练数据的局限。其影响深远：智能体大语言模型不再局限于模仿人类语料，而是通过合成数据、探索环境和实时适应，发展出**新的能力**。这为**超人类推理、工具编排、软件开发和现实世界中的自主性**铺平了道路。

- 智能体智能也重新定义了训练挑战。预训练不仅需高效地建立广泛先验知识，还需在万亿参数规模下避免不稳定。后训练则需在自然语料中智能体行为稀缺的情况下，生成可验证、可执行的行为。K2 通过结合 **MuonClip 稳定优化器**、**大规模智能体数据合成** 和**多信号强化学习（RL）**，成为当前最强的开源非“思考”模型之一。

- 你可以在这里在线试用：[kimi.com](https://www.kimi.com/)

- 以下是 [Kimi K2](https://moonshotai.github.io/Kimi-K2/) 的整体流程概览。

---

## 什么是 Kimi K2？

- Kimi K2 是一个**混合专家模型（MoE）**，总参数量为 **1 万亿**，但每次推理仅激活 **320 亿**参数，使其在保持强大性能的同时具备良好的计算效率。

- 更重要的是，Kimi K2 不仅是一个对话模型。它被设计用于**智能体行为**——如规划、推理、使用工具，并自主执行多步任务。

- Moonshot AI 发布了两个开源版本：

  - `Kimi-K2-Base`：原始预训练模型，适合研究和微调  
  - `Kimi-K2-Instruct`：经过后训练、具备指令跟随能力的模型，适用于反射性任务

---

## 架构设计

- Kimi K2 采用了类似 DeepSeek V3 的 MoE 架构，但在专家数量、注意力头数量等方面有所不同：使用了**更多专家、更少注意力头**，并引入了更优的负载均衡机制，防止少数专家主导训练（即“专家塌陷”）。

- 模型采用 **32/1024 的稀疏激活结构**，即每次仅激活 32 位专家。尽管稀疏度极高（推理时仅激活约 3% 的参数），K2 在各类任务上依然表现出色。

- 以下是简化示意图（来自 [Sebastian Raschka](https://x.com/rasbt/status/1944056316424577525/photo/1)）：

- 这种架构使 Kimi K2 能扩展至万亿参数规模，同时保持计算可行性。路由机制确保模型不同部分各司其职，训练动态则确保每位专家都能被充分利用。

---

## 预训练

### MuonClip 优化器

- **Token 效率与稳定性结合**：K2 引入了 **MuonClip**，将高效的 Muon 优化器与 **QK-Clip 机制**结合。Muon 提高了每个 token 的学习效率，但在大规模训练中会出现注意力 logits 不稳定增长的问题。QK-Clip 通过在 logits 超过阈值时对查询和键权重进行重缩放，抑制其增长。重要的是，这种重缩放不会改变当前步骤的前向/反向计算，从而保留了优化动态。该机制有效防止了训练过程中的损失爆炸，使 K2 能在 **15.5T tokens 上稳定训练，未出现发散**。

- **基于公式的裁剪机制**：对于每个注意力头（h），其最大注意力 logits 为：

  \[
  S^{h}_{\max} = \frac{1}{\sqrt{d}} \max_{X \in B} \max_{i,j} Q^{h}_i {K^h_j}^\top
  \]

  当 \( S^{h}_{\max} > \tau \) 时，权重将被重缩放：

  \[
  W^h_q \leftarrow W^h_q \cdot \sqrt{\gamma_h}, \quad W^h_k \leftarrow W^h_k \cdot \sqrt{\gamma_h}
  \]

  其中 \( \gamma_h = \min(1, \tau/S^{h}_{\max}) \)。这种**按头裁剪**机制最小化了不必要的干预，同时保证了 logits 的有界性。

---

### Token 效用与合成改写

- **知识改写**：K2 不采用多轮重复训练（易导致过拟合），而是引入**合成改写流水线**，包括：风格与视角多样的提示、块级自回归重写以保持全局一致性、语义保真度检查以确保对齐。通过改写，知识 token 被有效放大，同时不牺牲准确性。例如，SimpleQA 的准确率从多轮训练的 23.8% 提升至 28.9%。

- **数学增强**：数学语料被改写为逐步“学习笔记”，灵感来自 SwallowMath。这种方式迫使模型内化推理步骤，提升其在竞赛级问题上的表现。此外，多语言数学资源被翻译为英文，增强了多样性与推理鲁棒性。

---

### 模型架构

- **万亿参数 MoE 的稀疏扩展**：K2 使用 384 位专家，稀疏度为 48（每 token 激活 8 位）。实验表明，在相同 FLOPs 下，更高稀疏度可降低验证损失，相比稀疏度为 8 的模型，**FLOPs 减少 1.69 倍**。

- **注意力头权衡**：K2 将注意力头数量减半至 64（相比 DeepSeek-V3 的翻倍策略）。实验显示，性能提升仅 0.5–1.2%，但在 128k token 长度下推理 FLOPs 增加高达 83%。因此，K2 优先考虑**长上下文效率**而非微小性能提升。

---

### 训练基础设施

- **集群与并行策略**：训练在 **NVIDIA H800 集群**上进行，每节点 2TB 内存，采用 16 路流水线并行、16 路专家并行和 ZeRO-1 数据并行。

- **内存优化**：采用 FP8-E4M3 激活压缩、选择性重计算（SwiGLU/LayerNorm）以及 CPU 激活卸载，使万亿参数模型在有限 GPU 内存下稳定训练。

- **训练配方**：共处理 15.5T tokens，前 10T tokens 使用恒定学习率 2e-4，后 5.5T 使用余弦衰减，最后进行退火阶段。上下文长度通过 **YaRN** 从 4k 扩展至 32k 再到 128k。训练曲线全程无波动。

---

## 后训练

### 基于智能体数据的监督微调（SFT）

- **指令多样性**：通过人工标注、提示工程改写和评判模型自动过滤，合成了多样化的指令微调数据集。

- **智能体合成流水线**：借鉴 ACEBench，K2 构建了**混合流水线**，结合模拟环境与真实执行沙箱（如带单元测试的编程任务）。流程包括：(1) 生成合成与真实工具规范（20k+ 工具，3k+ MCP）；(2) 创建多样化智能体与工具集；(3) 生成基于评分标准的任务；(4) 模拟多轮轨迹并进行评分验证。这确保了**覆盖率与真实性**。

---

### 强化学习（RL）

- **双重奖励信号**：RL 使用可验证任务（数学、逻辑、编程等）与自评评分奖励（如创造力、安全性等主观领域）。评判模型持续优化评分权重，将主观判断锚定在可验证性能上。

- **训练创新**：引入预算控制机制惩罚冗长输出，PTX 损失集成保留高质量预训练知识，温度衰减策略平衡探索与收敛。最终，RL 不仅提升了准确性，也增强了**与人类价值观的对齐**。

---

### RL 基础设施

- **检查点引擎**：采用分布式检查点系统，在节点间广播完整参数状态，避免通过 NFS 重分发参数，减少同步开销，在万亿参数规模下实现**30 秒内更新**。

- **智能体 rollout**：通过**部分 rollout**、环境并行化和延迟摊销加速长程任务。RL 框架类似 Gym 接口，支持任意新环境的无缝集成。

---

## 评测结果

### 编程与工程能力

- SWE-bench Verified（单轮智能体）：**65.8%**，接近 Claude 4 Opus（72.5%）  
- LiveCodeBench v6：**53.7%**，超越 GPT-4.1 和 Claude Sonnet  
- OJBench：**27.1%**，优于 Gemini 2.5 Flash（19.5%）

这些结果使 K2 成为当前**最强的开源编程模型**之一。

---

### 智能体工具使用

- Tau2-Bench（多轮工具编排）：**66.1 Pass@1**  
- AceBench：**76.5 准确率**，超越 DeepSeek-V3 和 Claude Sonnet  

展现出强大的** grounded 工具使用推理能力**，是智能体智能的核心支柱。

---

### 数学与 STEM

- AIME 2025：**49.5%**，远超 Qwen3（24.7%）  
- GPQA-Diamond：**75.1%**，与 Claude Opus 相当  
- HMMT 2025：**38.8%**，开源模型中最佳  

验证了“学习笔记改写”与“RL 可验证任务集成”的有效性。

---

### 通用与长上下文能力

- MMLU：**89.5%**，与专有模型相当  
- MMLU-Redux：**92.7%**，开源模型中最佳  
- LongBench v2：**49.1%**，与 GPT-4.1 竞争力相当  
- DROP：**93.5%** 事实推理准确率  

K2 不仅是专用模型，更是**推理、事实性和长上下文任务上的强通用模型**。

---

## MuonClip 优化总结

- 训练万亿参数模型极具挑战，大多数模型因注意力机制不稳定（尤其是 logits 爆炸）而失败。

- Kimi K2 引入了自定义优化器 **MuonClip**，这是 Muon 优化器的改进版，专为大规模 MoE 模型设计。

- 其核心创新是 **qk-clip**，在每一步训练中动态重缩放注意力查询和键，确保 logits 保持在安全范围内。

---

## 智能体智能作为一种新范式

智能体智能将大语言模型的**操作基础**从被动完成引擎转变为**自适应、自主系统**。通过**工具发现**、**自我评估**、**基于评分标准的对齐机制**以及**混合真实/合成环境**，K2 等模型指向了新一代 AI 的方向：能够持续扩展其能力边界。

智能体模型不再受限于静态预训练数据的边际收益递减，而是生成自身的**行动轨迹**和**错误驱动的改进**，成为**自我维持的学习者**。这不仅对研究具有重要意义（在智能体数据缺乏的情况下，扩展法则可能趋于平缓），也对现实部署至关重要——自主性、可靠性和工具使用能力不可或缺。

K2 表明，构建此类系统需要在**优化（MuonClip）**、**数据策划（合成改写与工具流水线）**、**强化学习（RLVR + 评分奖励）**和**基础设施（检查点引擎、智能体 rollout）**等方面进行创新。它不仅是一个模型，更是未来 AI 系统的框架——模糊**静态基础模型**与**交互式、演化中的智能体**之间的界限。

---

## 参考资料

- [Kimi K2 和“DeepSeek 时刻”何时成为常态](https://www.interconnects.ai/p/kimi-k2-and-when-deepseek-moments)  
- [Kimi K2 GitHub](https://github.com/MoonshotAI/Kimi-K2)

---







# 参考

1. [Kimi K2](https://aman.ai/primers/ai/kimi-K2/)

[最新重量级报告，Kimi 开源 K2技术「Make Kimi Great Again」](https://mp.weixin.qq.com/s/_PaLe6Wi0jH3FCsEN2m9lw)    翻译 最上面的总结









